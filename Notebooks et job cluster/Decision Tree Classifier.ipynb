{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7e3e769",
   "metadata": {},
   "source": [
    "# Modèle Decision Tree\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34949573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, DateType\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StringIndexer, CountVectorizer, NGram, VectorAssembler, ChiSqSelector\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Variables de contexte"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ec7d37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark1 = SparkSession.builder\\\n",
    "            .master(\"local[16]\")\\\n",
    "            .appName(\"DT_Twitter\")\\\n",
    "            .getOrCreate()\n",
    "\n",
    "path = \"../resources/testdata.csv\"\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"target\", IntegerType(), True),\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"date\", StringType(), True),\n",
    "    StructField(\"query\", StringType(), True),\n",
    "    StructField(\"author\", StringType(), True),\n",
    "    StructField(\"tweet\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chargement du dataset et séparation train/test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "736929c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark1.read.csv(path,\n",
    "                     inferSchema=True,\n",
    "                     header=False,\n",
    "                     schema=schema)\n",
    "\n",
    "df.dropna()\n",
    "\n",
    "(train_set, test_set) = df.randomSplit([0.80, 0.20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54567ad4",
   "metadata": {},
   "source": [
    "## HashingTF - IDF (paramètres par défaut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43e13a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"tweet\", outputCol=\"words\")\n",
    "hashtf = HashingTF(inputCol=\"words\", outputCol='tf')\n",
    "idf = IDF(inputCol='tf', outputCol=\"features\")\n",
    "label_stringIdx = StringIndexer(inputCol = \"target\", outputCol = \"label\")\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, hashtf, idf, label_stringIdx, dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95303d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4\n",
      "Precision: 0.6693768996960487\n",
      "Recall: 0.4\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 10.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipelineFit = pipeline.fit(train_set)\n",
    "\n",
    "predictions = pipelineFit.transform(test_set)\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44970a31",
   "metadata": {},
   "source": [
    "## HashingTF - IDF (paramètres customisés)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ef25a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"tweet\", outputCol=\"words\")\n",
    "hashtf = HashingTF(numFeatures=2**16, inputCol=\"words\", outputCol='tf')\n",
    "idf = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "label_stringIdx = StringIndexer(inputCol = \"target\", outputCol = \"label\")\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "pipeline = Pipeline(stages=[tokenizer, hashtf, idf, label_stringIdx, dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de08b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipelineFit = pipeline.fit(train_set)\n",
    "\n",
    "predictions = pipelineFit.transform(test_set)\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca834cd",
   "metadata": {},
   "source": [
    "## CountVectorizer - IDF (paramètres par défaut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f6b35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"tweet\", outputCol=\"words\")\n",
    "cv = CountVectorizer(inputCol=\"words\", outputCol='cv')\n",
    "idf = IDF(inputCol='cv', outputCol=\"features\")\n",
    "label_stringIdx = StringIndexer(inputCol = \"target\", outputCol = \"label\")\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, cv, idf, label_stringIdx, dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5069e5ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pipelineFit = pipeline.fit(train_set)\n",
    "\n",
    "predictions = pipelineFit.transform(test_set)\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171b59b8",
   "metadata": {},
   "source": [
    "## CountVectorizer - IDF (paramètres customisés)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d3b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"tweet\", outputCol=\"words\")\n",
    "cv = CountVectorizer(vocabSize=2**16, inputCol=\"words\", outputCol='cv')\n",
    "idf = IDF(inputCol='cv', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "label_stringIdx = StringIndexer(inputCol = \"target\", outputCol = \"label\")\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, cv, idf, label_stringIdx, dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10c6be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipelineFit = pipeline.fit(train_set)\n",
    "\n",
    "predictions = pipelineFit.transform(test_set)\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbddca0",
   "metadata": {},
   "source": [
    "# CountVectorizer + NGram + ChisQSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08f71e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trigrams(inputCol=[\"tweet\",\"target\"], n=3):\n",
    "    \n",
    "    tokenizer = [Tokenizer(inputCol=\"tweet\", outputCol=\"words\")]\n",
    "    \n",
    "    ngrams = [\n",
    "        NGram(n=i, inputCol=\"words\", outputCol=\"{0}_grams\".format(i))\n",
    "        for i in range(1, n + 1)\n",
    "    ]\n",
    "\n",
    "    cv = [\n",
    "        CountVectorizer(vocabSize=2**14,inputCol=\"{0}_grams\".format(i),\n",
    "            outputCol=\"{0}_tf\".format(i))\n",
    "        for i in range(1, n + 1)\n",
    "    ]\n",
    "    \n",
    "    idf = [IDF(inputCol=\"{0}_tf\".format(i), outputCol=\"{0}_tfidf\".format(i), minDocFreq=5) for i in range(1, n + 1)]\n",
    "\n",
    "    assembler = [VectorAssembler(\n",
    "        inputCols=[\"{0}_tfidf\".format(i) for i in range(1, n + 1)],\n",
    "        outputCol=\"rawFeatures\"\n",
    "    )]\n",
    "    \n",
    "    label_stringIdx = [StringIndexer(inputCol = \"target\", outputCol = \"label\")]\n",
    "    \n",
    "    selector = [ChiSqSelector(numTopFeatures=2**14,featuresCol='rawFeatures', outputCol=\"features\")]\n",
    "    \n",
    "    dt = [DecisionTreeClassifier()]\n",
    "    \n",
    "    return Pipeline(stages=tokenizer + ngrams + cv + idf + assembler + label_stringIdx + selector + dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c907f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipelineFit = build_trigrams().fit(train_set)\n",
    "\n",
    "predictions = pipelineFit.transform(test_set)\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
